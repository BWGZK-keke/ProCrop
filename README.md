# ProCrop ðŸš€

**ProCrop** â€” *Learning Aesthetic Image Cropping from Professional Compositions*  
Code and dataset for the paper: **ProCrop: Learning Aesthetic Image Cropping from Professional Compositions**  
ðŸ“„ *arXiv:2505.22490* â€” Ke Zhang, Tianyu Ding, Jiachen Jiang, Tianyi Chen, Ilya Zharkov, Vishal M. Patel, Luming Liang :contentReference[oaicite:1]{index=1}

---

## ðŸ“˜ Overview

Image cropping is a fundamental step in visual content creation and enhancement. Traditional rule-based heuristics and existing learning-based methods often struggle to match the aesthetics of professional photographers. **ProCrop** addresses this gap by learning aesthetic cropping styles directly from professional compositions.

ProCrop introduces:
- A **retrieval-based aesthetic cropping model** that leverages professional images to guide crop selection.
- A **large-scale composition-aware dataset** with 242K weakly annotated images generated through an iterative out-painting and crop proposal refinement pipeline.
- State-of-the-art performance in both **supervised** and **weakly supervised** settings â€” surpassing previous methods and matching fully supervised baselines. :contentReference[oaicite:2]{index=2}

---
## Create Environment
conda create -n procrop python=3.11 -y

## ðŸ“¦ Repository Contents

```

ðŸ“ ProCrop/
To be uploaded
````

---

## ðŸ§  Features

âœ”ï¸ **Professional composition guidance**  
Leverages features from professional photography to drive cropping decisions.

âœ”ï¸ **Large weakly annotated dataset**  
Contains ~242K images and diverse crop proposals generated via out-painting and iterative refinement.

âœ”ï¸ **Flexible training modes**  
Supports both fully supervised and weakly supervised learning.

âœ”ï¸ **State-of-the-art performance**  
Outperforms prior methods and rivals supervised baselines when trained on the ProCrop dataset.

---

## ðŸš€ Quick Start
## Step 1: Preprocess the Query and Retrieval Datasets

We adapt code from **RALF** (https://github.com/CyberAgentAILab/RALF) for this step.  
You may skip this step if you are using the **pre-generated queryâ€“retrieval relationship file**.

### 1.1 Extract Query Embeddings
- Extract **SAM embeddings** for the **query dataset**.
- Store the embeddings in an **HDFS file**.

### 1.2 Extract Retrieval Embeddings
- Extract **SAM embeddings** for the **retrieval dataset**.
- Store the embeddings in an **HDFS file**.

### 1.3 Compute Queryâ€“Retrieval Relationships
- For each query image, compute the **top-k most similar images** from the retrieval dataset.
- Save the **queryâ€“retrieval correspondences** to an **HDFS file**.

Step 2: Retrieval-based auto Cropping


## ðŸ“ Dataset

ProCrop includes:

* **Weakly annotated images** generated by out-painting professional images.
* **Diverse crop proposals** obtained through iterative refinement.
* Designed to capture *composition-aware aesthetics* and improve generalization.

> Dataset download and preparation instructions can be found in `datasets/README.md`.

---

## ðŸ“„ Citation

If you use this code or dataset in your research, please cite:

```bibtex
@article{ProCrop2025,
  title={ProCrop: Learning Aesthetic Image Cropping from Professional Compositions},
  author={Zhang, Ke and Ding, Tianyu and Jiang, Jiachen and Chen, Tianyi and Zharkov, Ilya and Patel, Vishal M. and Liang, Luming},
  journal={arXiv preprint arXiv:2505.22490},
  year={2025}
}
```
---

## ðŸ“Œ Contact

For questions or collaborations:

* Open an issue
* Reach out to the authors via email (see paper)

---

Happy cropping! ðŸŽ¯

[1]: https://arxiv.org/abs/2505.22490 "[2505.22490] ProCrop: Learning Aesthetic Image Cropping from Professional Compositions"

