<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ProCrop: Learning Aesthetic Image Cropping from Professional Compositions</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      line-height: 1.6;
      max-width: 900px;
      margin: 0 auto;
      padding: 20px;
      background: #fdfdfd;
      color: #333;
    }
    h1 {
      font-size: 28px;
      margin-bottom: 0.3em;
      text-align: center;
    }
    h2 {
      font-size: 20px;
      margin-top: 1.5em;
    }
    .authors {
      font-size: 16px;
      text-align: center;
    }

    .links {
      margin-top: 20px;
      text-align: center;
    }

    .links a {
      display: inline-block;
      margin: 10px 10px 0 0;
      padding: 10px 16px;
      font-size: 0.95rem;
      font-weight: 600;
      text-decoration: none;
      color: #ffffff;
      background-color: #007acc;
      border-radius: 8px;
      transition: background-color 0.3s ease;
    }

    .links a:hover {
      background-color: #005fa3;
    }

    .links a[disabled] {
      background-color: #999999;
      pointer-events: none;
    }
    .figure {
      margin: 20px 0;
      text-align: center;
    }
    .figure img {
      max-width: 100%;
      border: 1px solid #ccc;
    }
    .abstract {
      background: #f5f5f5;
      padding: 15px;
      border-left: 5px solid #007acc;
    }
  </style>
</head>
<body>

  <h1>ProCrop: Learning Aesthetic Image Cropping from Professional Compositions</h1>

  <div class="authors">
    Ke Zhang<sup>1</sup> &nbsp;
    Tianyu Ding<sup>3&nbsp;‚Ä†</sup> &nbsp;
    Jiachen Jiang<sup>2</sup> &nbsp;
    Tianyi Chen<sup>3</sup> &nbsp;<br>
    Ilya Zharkov<sup>3</sup> &nbsp;
    Vishal M. Patel<sup>1</sup> &nbsp;
    Luming Liang<sup>3&nbsp;‚Ä†</sup> <br><br>
    <sup>1</sup>Johns Hopkins University &nbsp;&nbsp;
    <sup>2</sup>Ohio State University &nbsp;&nbsp;
    <sup>3</sup>Microsoft <br>
<!--     <a href="https://kongwanbianjinyu.github.io/Cat-AIR/">Project Site</a> -->
  </div>

<!--   <div class="links">
    <h2>Resources</h2>
    <a href="#">[Paper]</a>
    <a href="#">[Code]</a>
    <a href="#">[Model]</a>
  </div> -->
  <div class="links">
    <a href="https://arxiv.org/pdf/2505.21653" target="_blank">üìÑ Paper (arXiv)</a>
    <a href="#" onclick="alert('Code coming soon!')" style="background-color: #999999;">üíª Code (Coming Soon)</a>
    <a href="#" onclick="alert('Model coming soon!')" style="background-color: #999999;">üß† Model (Coming Soon)</a>
    <a href="#" onclick="alert('Dataset coming soon!')" style="background-color: #999999;">üìÅ Dataset (Coming Soon)</a>
  </div>

  <div class="figure">
    <h2>Figure</h2>
    <img src="pipeline.png" alt="ProCrop overview figure">
    <p><i>The pipeline of ProCrop. Given an input image, ProCrop retrieves compositionally similar professional images and generates a textual description, which guide the model to produce aesthetically enhanced crops along with corresponding aesthetic scores.</i></p>
  </div>

  <div class="abstract">
    <h2>Abstract</h2>
    <p>
      Image cropping is crucial for enhancing the visual appeal and narrative impact of photographs,
      yet existing rule-based and data-driven approaches often lack diversity or require annotated training data.
      We introduce ProCrop, a retrieval-based method that leverages professional photography to guide cropping decisions.
      By fusing features from professional photographs with those of the query image,
      ProCrop learns from professional compositions, significantly boosting performance.
      Additionally, we present a large-scale dataset of 242K weakly-annotated images,
      generated by out-painting professional images and iteratively refining diverse crop proposals.
      This composition-aware dataset generation offers diverse high-quality crop proposals guided by aesthetic principles
      and becomes the largest publicly available dataset for image cropping.
      Extensive experiments show that ProCrop significantly outperforms existing methods in both supervised and weakly-supervised settings.
      Notably, when trained on the new dataset, our ProCrop surpasses previous weakly-supervised methods and even matches fully supervised approaches.
      Both the code and dataset will be made publicly available to advance research in image aesthetics and composition analysis.
    </p>
  </div>

</body>
</html>
